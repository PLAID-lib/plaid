{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Examples\n",
    "\n",
    "This Jupyter Notebook demonstrates various use cases for the Dataset class, including:\n",
    "\n",
    "1. Initializing an Empty Dataset and Adding Samples\n",
    "2. Retrieving and Manipulating Samples from a Dataset\n",
    "3. Performing Operations on the Dataset\n",
    "4. Saving and Loading Datasets from directories or files\n",
    "\n",
    "This notebook provides detailed examples of using the Dataset class to manage data, Samples, and information within a PLAID Dataset. It is intended for documentation purposes and familiarization with the PLAID library.\n",
    "\n",
    "**Each section is documented and explained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and functions\n",
    "import Muscat.Containers.ElementsDescription as ElementsDescription\n",
    "from Muscat.Bridges.CGNSBridge import MeshToCGNS\n",
    "from Muscat.Containers import MeshCreationTools as MCT\n",
    "\n",
    "from plaid.containers.dataset import Dataset\n",
    "from plaid.containers.sample import Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dict util\n",
    "def dprint(name: str, dictio: dict, end: str = \"\\n\"):\n",
    "    print(name, '{')\n",
    "    for key, value in dictio.items():\n",
    "\t    print(\"    \", key, ':', value)\n",
    "\n",
    "    print('}', end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Initializing an Empty Dataset and Samples construction\n",
    "\n",
    "This section demonstrates how to initialize an empty Dataset and handle Samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an empty Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---# Empty Dataset\n",
      "dataset=Dataset(0 samples, 0 scalars, 0 fields)\n"
     ]
    }
   ],
   "source": [
    "print(\"#---# Empty Dataset\")\n",
    "dataset = Dataset()\n",
    "print(f\"{dataset=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---# Empty Sample\n",
      "sample_01 = Sample(0 scalars, 0 timestamps, 0 fields, no tree)\n"
     ]
    }
   ],
   "source": [
    "# Create Sample\n",
    "points = np.array([\n",
    "        [0.0, 0.0],\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "        [0.0, 1.0],\n",
    "        [0.5, 1.5],\n",
    "    ])\n",
    "\n",
    "triangles = np.array([\n",
    "        [0, 1, 2],\n",
    "        [0, 2, 3],\n",
    "        [2, 4, 3],\n",
    "    ])\n",
    "\n",
    "bars = np.array([\n",
    "        [0, 1],\n",
    "        [0, 2]\n",
    "    ])\n",
    "\n",
    "Mesh = MCT.CreateMeshOfTriangles(points, triangles)\n",
    "elbars = Mesh.GetElementsOfType(ElementsDescription.Bar_2)\n",
    "elbars.AddNewElements(bars, [1, 2])\n",
    "cgns_mesh = MeshToCGNS(Mesh)\n",
    "\n",
    "# Initialize an empty Sample\n",
    "print(\"#---# Empty Sample\")\n",
    "sample_01 = Sample()\n",
    "print(f\"{sample_01 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_01 = Sample(0 scalars, 1 timestamp, 1 field)\n"
     ]
    }
   ],
   "source": [
    "# Add a CGNS tree structure to the Sample\n",
    "sample_01.add_tree(cgns_mesh)\n",
    "print(f\"{sample_01 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_01 = Sample(1 scalar, 1 timestamp, 1 field)\n"
     ]
    }
   ],
   "source": [
    "# Add a scalar to the Sample\n",
    "sample_01.add_scalar('rotation', np.random.randn())\n",
    "print(f\"{sample_01 = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Sample general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---# Empty Sample\n",
      "sample_02 = Sample(0 scalars, 0 timestamps, 0 fields, no tree)\n"
     ]
    }
   ],
   "source": [
    "# Initialize another empty Sample\n",
    "print(\"#---# Empty Sample\")\n",
    "sample_02 = Sample()\n",
    "print(f\"{sample_02 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_02 = Sample(1 scalar, 0 timestamps, 0 fields, no tree)\n"
     ]
    }
   ],
   "source": [
    "# Add a scalar to the second Sample\n",
    "sample_02.add_scalar('rotation', np.random.randn())\n",
    "print(f\"{sample_02 = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Sample CGNS tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---# Empty Sample\n",
      "- \"CGNSTree\"(CGNSTree_t), 2 children, data(<class 'NoneType'>): None\n",
      "    - \"CGNSLibraryVersion\"(CGNSLibraryVersion_t), 0 children, data(<class 'numpy.ndarray'>): [3.4]\n",
      "    - \"Base_2_2\"(CGNSBase_t), 3 children, data(<class 'numpy.ndarray'>): [2 2]\n",
      "        - \"Bulk\"(FamilyName_t), 0 children, data(<class 'numpy.ndarray'>): b'Bulk'\n",
      "        - \"Zone\"(Zone_t), 8 children, data(<class 'numpy.ndarray'>): [[5 5 1]]\n",
      "            - \"ZoneType\"(ZoneType_t), 0 children, data(<class 'numpy.ndarray'>): b'Unstructured'\n",
      "            - \"FamilyName\"(FamilyName_t), 0 children, data(<class 'numpy.ndarray'>): b'Bulk'\n",
      "            - \"GridCoordinates\"(GridCoordinates_t), 2 children, data(<class 'NoneType'>): None\n",
      "                - \"CoordinateX\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0.  1.  1.  0.  0.5]\n",
      "                - \"CoordinateY\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0.  0.  1.  1.  1.5]\n",
      "            - \"Elements_BAR_2\"(Elements_t), 2 children, data(<class 'numpy.ndarray'>): [3 0]\n",
      "                - \"ElementRange\"(IndexRange_t), 0 children, data(<class 'numpy.ndarray'>): [1 2]\n",
      "                - \"ElementConnectivity\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1 2 1 3]\n",
      "            - \"Elements_TRI_3\"(Elements_t), 2 children, data(<class 'numpy.ndarray'>): [5 0]\n",
      "                - \"ElementRange\"(IndexRange_t), 0 children, data(<class 'numpy.ndarray'>): [3 5]\n",
      "                - \"ElementConnectivity\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1 2 3 1 3 4 3 5 4]\n",
      "            - \"PointData\"(FlowSolution_t), 2 children, data(<class 'NoneType'>): None\n",
      "                - \"GridLocation\"(GridLocation_t), 0 children, data(<class 'numpy.ndarray'>): b'Vertex'\n",
      "                - \"OriginalIds\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0 1 2 3 4]\n",
      "            - \"CellData\"(FlowSolution_t), 2 children, data(<class 'NoneType'>): None\n",
      "                - \"GridLocation\"(GridLocation_t), 0 children, data(<class 'numpy.ndarray'>): b'CellCenter'\n",
      "                - \"OriginalIds\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1 2 0 1 2]\n",
      "            - \"Elements_Selections\"(ZoneBC_t), 1 children, data(<class 'NoneType'>): None\n",
      "                - \"2D\"(BC_t), 3 children, data(<class 'numpy.ndarray'>): b'FamilySpecified'\n",
      "                    - \"ElementList\"(IndexArray_t), 0 children, data(<class 'numpy.ndarray'>): [[3 4 5]]\n",
      "                    - \"FamilyName\"(FamilyName_t), 0 children, data(<class 'numpy.ndarray'>): b'Null'\n",
      "                    - \"GridLocation\"(GridLocation_t), 0 children, data(<class 'numpy.ndarray'>): b'CellCenter'\n",
      "        - \"Time\"(BaseIterativeData_t), 2 children, data(<class 'numpy.ndarray'>): [1]\n",
      "            - \"IterationValues\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1]\n",
      "            - \"TimeValues\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a third empty Sample\n",
    "print(\"#---# Empty Sample\")\n",
    "sample_03 = Sample()\n",
    "sample_03.add_scalar('speed', np.random.randn())\n",
    "sample_03.add_scalar('rotation', sample_01.get_scalar('rotation'))\n",
    "sample_03.add_tree(cgns_mesh)\n",
    "\n",
    "# Show Sample CGNS content\n",
    "sample_03.show_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- \"CGNSTree\"(CGNSTree_t), 2 children, data(<class 'NoneType'>): None\n",
      "    - \"CGNSLibraryVersion\"(CGNSLibraryVersion_t), 0 children, data(<class 'numpy.ndarray'>): [3.4]\n",
      "    - \"Base_2_2\"(CGNSBase_t), 3 children, data(<class 'numpy.ndarray'>): [2 2]\n",
      "        - \"Bulk\"(FamilyName_t), 0 children, data(<class 'numpy.ndarray'>): b'Bulk'\n",
      "        - \"Zone\"(Zone_t), 8 children, data(<class 'numpy.ndarray'>): [[5 5 1]]\n",
      "            - \"ZoneType\"(ZoneType_t), 0 children, data(<class 'numpy.ndarray'>): b'Unstructured'\n",
      "            - \"FamilyName\"(FamilyName_t), 0 children, data(<class 'numpy.ndarray'>): b'Bulk'\n",
      "            - \"GridCoordinates\"(GridCoordinates_t), 2 children, data(<class 'NoneType'>): None\n",
      "                - \"CoordinateX\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0.  1.  1.  0.  0.5]\n",
      "                - \"CoordinateY\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0.  0.  1.  1.  1.5]\n",
      "            - \"Elements_BAR_2\"(Elements_t), 2 children, data(<class 'numpy.ndarray'>): [3 0]\n",
      "                - \"ElementRange\"(IndexRange_t), 0 children, data(<class 'numpy.ndarray'>): [1 2]\n",
      "                - \"ElementConnectivity\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1 2 1 3]\n",
      "            - \"Elements_TRI_3\"(Elements_t), 2 children, data(<class 'numpy.ndarray'>): [5 0]\n",
      "                - \"ElementRange\"(IndexRange_t), 0 children, data(<class 'numpy.ndarray'>): [3 5]\n",
      "                - \"ElementConnectivity\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1 2 3 1 3 4 3 5 4]\n",
      "            - \"PointData\"(FlowSolution_t), 3 children, data(<class 'NoneType'>): None\n",
      "                - \"GridLocation\"(GridLocation_t), 0 children, data(<class 'numpy.ndarray'>): b'Vertex'\n",
      "                - \"OriginalIds\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0 1 2 3 4]\n",
      "                - \"temperature\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0.32907168 0.011283   0.44590603 0.30966153 0.56441073]\n",
      "            - \"CellData\"(FlowSolution_t), 2 children, data(<class 'NoneType'>): None\n",
      "                - \"GridLocation\"(GridLocation_t), 0 children, data(<class 'numpy.ndarray'>): b'CellCenter'\n",
      "                - \"OriginalIds\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1 2 0 1 2]\n",
      "            - \"Elements_Selections\"(ZoneBC_t), 1 children, data(<class 'NoneType'>): None\n",
      "                - \"2D\"(BC_t), 3 children, data(<class 'numpy.ndarray'>): b'FamilySpecified'\n",
      "                    - \"ElementList\"(IndexArray_t), 0 children, data(<class 'numpy.ndarray'>): [[3 4 5]]\n",
      "                    - \"FamilyName\"(FamilyName_t), 0 children, data(<class 'numpy.ndarray'>): b'Null'\n",
      "                    - \"GridLocation\"(GridLocation_t), 0 children, data(<class 'numpy.ndarray'>): b'CellCenter'\n",
      "        - \"Time\"(BaseIterativeData_t), 2 children, data(<class 'numpy.ndarray'>): [1]\n",
      "            - \"IterationValues\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [1]\n",
      "            - \"TimeValues\"(DataArray_t), 0 children, data(<class 'numpy.ndarray'>): [0.]\n"
     ]
    }
   ],
   "source": [
    "# Add a field to the third empty Sample\n",
    "sample_03.add_field('temperature', np.random.rand(5), \"Zone\", \"Base_2_2\")\n",
    "sample_03.show_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_03 = Sample(2 scalars, 1 timestamp, 2 fields)\n",
      "\n",
      "sample_03.get_scalar_names() = ['rotation', 'speed']\n",
      "sample_03.get_scalar('speed') = -0.14388971011694415\n",
      "sample_03.get_scalar('rotation') = 0.805459944043219\n",
      "\n",
      "sample_03.get_field_names() = ['OriginalIds', 'temperature']\n",
      "sample_03.get_field('temperature') = array([0.32907168, 0.011283  , 0.44590603, 0.30966153, 0.56441073])\n"
     ]
    }
   ],
   "source": [
    "# Print sample general data\n",
    "print(f\"{sample_03 = }\", end=\"\\n\\n\")\n",
    "\n",
    "# Print sample scalar data\n",
    "print(f\"{sample_03.get_scalar_names() = }\")\n",
    "print(f\"{sample_03.get_scalar('speed') = }\")\n",
    "print(f\"{sample_03.get_scalar('rotation') = }\", end=\"\\n\\n\")\n",
    "\n",
    "# Print sample scalar data\n",
    "print(f\"{sample_03.get_field_names() = }\")\n",
    "print(f\"{sample_03.get_field('temperature') = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Performing Operations on the Dataset\n",
    "\n",
    "This section demonstrates how to add Samples to the Dataset, add information, and access data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Samples in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added_sample_id = 2\n"
     ]
    }
   ],
   "source": [
    "# Add Samples by id in the Dataset\n",
    "dataset.set_sample(id=0, sample=sample_01)\n",
    "dataset.set_sample(1, sample_02)\n",
    "\n",
    "# Add unique Sample and automatically create its id\n",
    "added_sample_id = dataset.add_sample(sample_03)\n",
    "print(f\"{added_sample_id = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add and display information to the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-10 13:10:16,584:WARNING:dataset.py:set_infos(570)]:infos not empty, replacing it anyway\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset info = {\n",
      "    \"legal\": {\n",
      "        \"owner\": \"Safran\"\n",
      "    }\n",
      "}\n",
      "\n",
      "dataset info = {\n",
      "    \"legal\": {\n",
      "        \"owner\": \"Safran\",\n",
      "        \"license\": \"CC0\"\n",
      "    }\n",
      "}\n",
      "\n",
      "*********************** dataset infos **********************\n",
      "legal\n",
      "  owner:Safran\n",
      "  license:CC0\n",
      "data_description\n",
      "  number_of_samples:0\n",
      "  number_of_splits:0\n",
      "************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add node information to the Dataset\n",
    "dataset.add_info(\"legal\", \"owner\", \"Safran\")\n",
    "\n",
    "# Retrive dataset information\n",
    "import json\n",
    "dataset_info = dataset.get_infos()\n",
    "print(\"dataset info =\", json.dumps(dataset_info, sort_keys=False, indent=4), end=\"\\n\\n\")\n",
    "\n",
    "# Overwrite information (logger will display warnings)\n",
    "infos = {\"legal\": {\"owner\": \"Safran\", \"license\": \"CC0\"}}\n",
    "dataset.set_infos(infos)\n",
    "\n",
    "# Retrive dataset information\n",
    "dataset_info = dataset.get_infos()\n",
    "print(\"dataset info =\", json.dumps(dataset_info, sort_keys=False, indent=4), end=\"\\n\\n\")\n",
    "\n",
    "# Add tree information to the Dataset (logger will display warnings)\n",
    "dataset.add_infos(\"data_description\", {\"number_of_samples\" : 0, \"number_of_splits\": 0})\n",
    "\n",
    "# Pretty print dataset information\n",
    "dataset.print_infos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of specific Samples in a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get samples from ids = {\n",
      "     0 : Sample(1 scalar, 1 timestamp, 2 fields)\n",
      "     1 : Sample(1 scalar, 0 timestamps, 0 fields, no tree)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "get_samples_from_ids = dataset.get_samples(ids=[0, 1])\n",
    "dprint(\"get samples from ids =\", get_samples_from_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of Sample ids in a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_sample_ids = [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Print sample IDs\n",
    "print(\"get_sample_ids =\", dataset.get_sample_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Dataset general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = Dataset(3 samples, 2 scalars, 2 fields)\n",
      "length of dataset = 3\n"
     ]
    }
   ],
   "source": [
    "# Print the Dataset\n",
    "print(f\"{dataset = }\")\n",
    "print(\"length of dataset =\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a list of Sample to a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added_ids = array([0, 1, 2])\n",
      "dataset = Dataset(3 samples, 2 scalars, 2 fields)\n"
     ]
    }
   ],
   "source": [
    "# Create a new Dataset and add multiple samples\n",
    "dataset = Dataset()\n",
    "samples = [sample_01, sample_02, sample_03]\n",
    "added_ids = dataset.add_samples(samples)\n",
    "print(f\"{added_ids = }\")\n",
    "print(f\"{dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to Samples data through Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset(0) = Sample(1 scalar, 1 timestamp, 2 fields)\n",
      "dataset[1] = Sample(1 scalar, 0 timestamps, 0 fields, no tree)\n",
      "dataset[2] = Sample(2 scalars, 1 timestamp, 2 fields)\n",
      "\n",
      "scalar of the first sample =  ['rotation']\n",
      "scalar of the second sample =  ['rotation']\n",
      "scalar of the third sample =  ['rotation', 'speed']\n"
     ]
    }
   ],
   "source": [
    "# Access Sample data with indexes through the Dataset\n",
    "print(f\"{dataset(0) = }\") # call strategy\n",
    "print(f\"{dataset[1] = }\") # getitem strategy\n",
    "print(f\"{dataset[2] = }\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"scalar of the first sample = \", dataset[0].get_scalar_names())\n",
    "print(\"scalar of the second sample = \", dataset[1].get_scalar_names())\n",
    "print(\"scalar of the third sample = \", dataset[2].get_scalar_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0].get_scalar('rotation') = 0.805459944043219\n",
      "dataset[1].get_scalar('rotation') = -0.19098996969943888\n",
      "dataset[2].get_scalar('rotation') = 0.805459944043219\n"
     ]
    }
   ],
   "source": [
    "# Access dataset information\n",
    "print(f\"{dataset[0].get_scalar('rotation') = }\")\n",
    "print(f\"{dataset[1].get_scalar('rotation') = }\")\n",
    "print(f\"{dataset[2].get_scalar('rotation') = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset scalars to tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.get_scalar_names() = ['rotation', 'speed']\n",
      "\n",
      "get rotation scalar =  {\n",
      "     rotation : [ 0.80545994 -0.19098997  0.80545994]\n",
      "}\n",
      "get speed scalar =  {\n",
      "     speed : [        nan         nan -0.14388971]\n",
      "}\n",
      "\n",
      "get specific scalars = {\n",
      "     speed : [        nan         nan -0.14388971]\n",
      "     rotation : [ 0.80545994 -0.19098997  0.80545994]\n",
      "}\n",
      "get all scalars = {\n",
      "     rotation : [ 0.80545994 -0.19098997  0.80545994]\n",
      "     speed : [        nan         nan -0.14388971]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print scalars in tabular format\n",
    "print(f\"{dataset.get_scalar_names() = }\", end=\"\\n\\n\")\n",
    "\n",
    "dprint(\"get rotation scalar = \", dataset.get_scalars_to_tabular(['rotation']))\n",
    "dprint(\"get speed scalar = \", dataset.get_scalars_to_tabular(['speed']), end=\"\\n\\n\")\n",
    "\n",
    "# Get specific scalars in tabular format\n",
    "dprint(\"get specific scalars =\", dataset.get_scalars_to_tabular(['speed', 'rotation']))\n",
    "dprint(\"get all scalars =\", dataset.get_scalars_to_tabular())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get all scalar arrays =  [[ 0.80545994         nan]\n",
      " [-0.19098997         nan]\n",
      " [ 0.80545994 -0.14388971]]\n"
     ]
    }
   ],
   "source": [
    "# Get specific scalars np.array\n",
    "print(\"get all scalar arrays = \", dataset.get_scalars_to_tabular(as_nparray=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fields in the dataset =  ['OriginalIds', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "# Print fields in the Dataset\n",
    "print(\"fields in the dataset = \", dataset.get_field_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Various operations on the Dataset\n",
    "\n",
    "This section demonstrates operations like merging datasets, adding tabular scalars, and setting information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a Dataset with a list of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_dataset = Dataset(3 samples, 2 scalars, 0 fields)\n"
     ]
    }
   ],
   "source": [
    "# Create another Dataset\n",
    "other_dataset = Dataset()\n",
    "nb_samples = 3\n",
    "samples = []\n",
    "for _ in range(nb_samples):\n",
    "    sample = Sample()\n",
    "    sample.add_scalar('rotation', np.random.rand() + 1.0)\n",
    "    sample.add_scalar('random_name', np.random.rand() - 1.0)\n",
    "    samples.append(sample)\n",
    "\n",
    "# Add a list of Samples\n",
    "other_dataset.add_samples(samples)\n",
    "print(f\"{other_dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge two Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before merge: dataset = Dataset(3 samples, 2 scalars, 2 fields)\n",
      "after merge: dataset = Dataset(6 samples, 3 scalars, 2 fields)\n",
      "\n",
      "dataset scalars =  {\n",
      "     random_name : [        nan         nan         nan -0.62982915 -0.46566811 -0.78302561]\n",
      "     rotation : [ 0.80545994 -0.19098997  0.80545994  1.60027144  1.30347629  1.38152767]\n",
      "     speed : [        nan         nan -0.14388971         nan         nan         nan]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Merge the other dataset with the main dataset\n",
    "print(f\"before merge: {dataset = }\")\n",
    "dataset.merge_dataset(other_dataset)\n",
    "print(f\"after merge: {dataset = }\", end=\"\\n\\n\")\n",
    "\n",
    "dprint(\"dataset scalars = \", dataset.get_scalars_to_tabular())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tabular scalars to a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = Dataset(9 samples, 4 scalars, 2 fields)\n",
      "dataset scalars = {\n",
      "     Tu : [       nan        nan        nan        nan        nan        nan\n",
      " 0.21829095 0.82499924 0.02937202]\n",
      "     random_name : [        nan         nan         nan -0.62982915 -0.46566811 -0.78302561\n",
      "  0.00520439  0.48192759  0.80240679]\n",
      "     rotation : [ 0.80545994 -0.19098997  0.80545994  1.60027144  1.30347629  1.38152767\n",
      "         nan         nan         nan]\n",
      "     speed : [        nan         nan -0.14388971         nan         nan         nan\n",
      "         nan         nan         nan]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Adding tabular scalars to the dataset\n",
    "new_scalars = np.random.rand(3, 2)\n",
    "dataset.add_tabular_scalars(new_scalars, names=['Tu', 'random_name'])\n",
    "\n",
    "print(f\"{dataset = }\")\n",
    "dprint(\"dataset scalars =\", dataset.get_scalars_to_tabular())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set additional information to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** dataset infos **********************\n",
      "legal\n",
      "  owner:Safran\n",
      "  license:CC0\n",
      "data_production\n",
      "  type:simulation\n",
      "  simulator:dummy\n",
      "************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infos = {\n",
    "    \"legal\": {\n",
    "        \"owner\": \"Safran\",\n",
    "        \"license\": \"CC0\"},\n",
    "    \"data_production\": {\n",
    "        \"type\": \"simulation\",\n",
    "        \"simulator\": \"dummy\"}\n",
    "}\n",
    "dataset.set_infos(infos)\n",
    "dataset.print_infos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Saving and Loading Dataset\n",
    "\n",
    "This section demonstrates how to save and load a Dataset from a directory or file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a Dataset as a file tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save dataset in: /tmp/test_safe_to_delete_860567559532\n"
     ]
    }
   ],
   "source": [
    "tmpdir = f'/tmp/test_safe_to_delete_{np.random.randint(1e10, 1e12)}'\n",
    "print(f\"Save dataset in: {tmpdir}\")\n",
    "\n",
    "dataset._save_to_dir_(tmpdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the number of Samples that can be loaded from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_samples = 9\n"
     ]
    }
   ],
   "source": [
    "empty_ds = Dataset()\n",
    "nb_samples = empty_ds._load_number_of_samples_(tmpdir)\n",
    "\n",
    "print(f\"{nb_samples = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Dataset from a directory via initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded_dataset_from_init = Dataset(9 samples, 4 scalars, 2 fields)\n",
      "multi_process_loaded_dataset = Dataset(9 samples, 4 scalars, 2 fields)\n"
     ]
    }
   ],
   "source": [
    "loaded_dataset_from_init = Dataset(tmpdir)\n",
    "print(f\"{loaded_dataset_from_init = }\")\n",
    "\n",
    "multi_process_loaded_dataset = Dataset(tmpdir, processes_number=3)\n",
    "print(f\"{multi_process_loaded_dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Dataset from a directory via the Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: dataset contains no sample\n",
      "loaded_dataset_from_class = Dataset(0 samples, 0 scalars, 0 fields)\n",
      "Warning: dataset contains no sample\n",
      "multi_process_loaded_dataset = Dataset(0 samples, 0 scalars, 0 fields)\n"
     ]
    }
   ],
   "source": [
    "loaded_dataset_from_class = Dataset.load_from_dir(tmpdir)\n",
    "print(f\"{loaded_dataset_from_class = }\")\n",
    "\n",
    "multi_process_loaded_dataset = Dataset.load_from_dir(tmpdir, processes_number=3)\n",
    "print(f\"{multi_process_loaded_dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset from a directory via a Dataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: dataset contains no sample\n",
      "loaded_dataset_from_instance = Dataset(0 samples, 0 scalars, 0 fields)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute '_load_from_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloaded_dataset_from_instance\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m multi_process_loaded_dataset \u001b[38;5;241m=\u001b[39m Dataset()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmulti_process_loaded_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_dir\u001b[49m(tmpdir)\u001b[38;5;66;03m#, processes_number=3)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmulti_process_loaded_dataset\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute '_load_from_dir'"
     ]
    }
   ],
   "source": [
    "loaded_dataset_from_instance = Dataset()\n",
    "loaded_dataset_from_instance._load_from_dir_(tmpdir)\n",
    "\n",
    "print(f\"{loaded_dataset_from_instance = }\")\n",
    "\n",
    "multi_process_loaded_dataset = Dataset()\n",
    "multi_process_loaded_dataset._load_from_dir_(tmpdir, processes_number=3)\n",
    "print(f\"{multi_process_loaded_dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataset to a TAR (Tape Archive) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save dataset in: /tmp/test_safe_to_delete_189043173033/test_file.plaid\n"
     ]
    }
   ],
   "source": [
    "tmpdir = f'/tmp/test_safe_to_delete_{np.random.randint(1e10,1e12)}'\n",
    "tmpfile = os.path.join(tmpdir, 'test_file.plaid')\n",
    "\n",
    "print(f\"Save dataset in: {tmpfile}\")\n",
    "dataset.save(tmpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset from a TAR (Tape Archive) file via Dataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = Dataset(9 samples, 4 scalars, 2 fields)\n",
      "new_dataset = Dataset(9 samples, 4 scalars, 2 fields)\n"
     ]
    }
   ],
   "source": [
    "new_dataset = Dataset()\n",
    "new_dataset.load(tmpfile)\n",
    "\n",
    "print(f\"{dataset = }\")\n",
    "print(f\"{new_dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset from a TAR (Tape Archive) file via initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = Dataset(9 samples, 4 scalars, 2 fields)\n",
      "new_dataset = Dataset(9 samples, 4 scalars, 2 fields)\n"
     ]
    }
   ],
   "source": [
    "new_dataset = Dataset(tmpfile)\n",
    "\n",
    "print(f\"{dataset = }\")\n",
    "print(f\"{new_dataset = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Splitting Examples\n",
    "\n",
    "This Jupyter Notebook demonstrates the usage of the split module using the PLAID library. It includes examples of:\n",
    "\n",
    "1. Initializing a Dataset\n",
    "2. Splitting a Dataset with ratios\n",
    "3. Splitting a Dataset with fixed sizes\n",
    "4. Splitting a Dataset with ratio and fixed Sizes\n",
    "5. Splitting a Dataset with custom split IDs\n",
    "\n",
    "This example demonstrates the usage of dataset splitting functions to divide a dataset into training, validation, and test sets. It provides examples of splitting the dataset using different methods and configurations.\n",
    "\n",
    "**Each section is documented and explained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and functions\n",
    "from plaid.utils.init_with_tabular import initialize_dataset_with_tabular_data\n",
    "from plaid.utils.split import split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dict util\n",
    "def dprint(name: str, dictio: dict):\n",
    "    print(name, '{')\n",
    "    for key, value in dictio.items():\n",
    "\t    print(\"    \", key, ':', value)\n",
    "\n",
    "    print('}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Initialize Dataset\n",
    "\n",
    "In this section, we create a dataset with random tabular data for testing purposes. The dataset will be used for subsequent splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = Dataset(70 samples, 7 scalars, 0 fields)\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset with random tabular data for testing purposes\n",
    "nb_scalars = 7\n",
    "nb_samples = 70\n",
    "tabular_data = {f'scalar_{j}': np.random.randn(nb_samples) for j in range(nb_scalars)}\n",
    "dataset = initialize_dataset_with_tabular_data(tabular_data)\n",
    "\n",
    "print(f\"{dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Splitting a Dataset with Ratios\n",
    "\n",
    "In this section, we split the dataset into training, validation, and test sets using specified ratios. We also have the option to shuffle the dataset during the split process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First split\n",
      "split = {\n",
      "     train : [ 5 66 23 52 63 26 48 56 41 19 15 64 32 16 12 22 31  8 33 40  9 58 13  6\n",
      " 36 46 53 55 65 17 57 24 62  0 30  7 37 27  4  3 61 18 28 25 51 10 38 21\n",
      " 49 47 59 45 42  2  1 14]\n",
      "     val : [34 20 35 50 67 39 68]\n",
      "     other : [43 44 60 54 69 29 11]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"# First split\")\n",
    "options = {\n",
    "    'shuffle': True,\n",
    "    'split_ratios': {\n",
    "        'train': 0.8,\n",
    "        'val': 0.1,\n",
    "    },\n",
    "}\n",
    "\n",
    "split = split_dataset(dataset, options)\n",
    "dprint(\"split =\", split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Splitting a Dataset with Fixed Sizes\n",
    "\n",
    "In this section, we split the dataset into training, validation, and test sets with fixed sample counts for each set. We can also choose to shuffle the dataset during the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Second split\n",
      "split = {\n",
      "     train : [52 41 65  8 30 40 42 36 29 28 55 12  3  7]\n",
      "     val : [46 33  5 59 68 18 53 67]\n",
      "     test : [11 37 58 61 64]\n",
      "     other : [ 0  6 16  9 66 63 15 27 23 31 34  4 47 14 60 39 50 51 62 24 38 22 26 25\n",
      " 43 17  2 69 21 13 19  1 20 56 32 44 10 49 57 54 35 48 45]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"# Second split\")\n",
    "options = {\n",
    "    'shuffle': True,\n",
    "    'split_sizes': {\n",
    "        'train': 14,\n",
    "        'val': 8,\n",
    "        'test': 5,\n",
    "    },\n",
    "}\n",
    "\n",
    "split = split_dataset(dataset, options)\n",
    "dprint(\"split =\", split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Splitting a Dataset with Ratios and Fixed Sizes\n",
    "\n",
    "In this section, we split the dataset into training, validation, and test sets with fixed sample counts and sample ratios for each set. We can also choose to shuffle the dataset during the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Third split\")\n",
    "options = {\n",
    "    'shuffle': True,\n",
    "    'split_ratios': {\n",
    "        'train': 0.7,\n",
    "        'test': 0.1,\n",
    "    },\n",
    "    'split_sizes': {\n",
    "        'val': 7\n",
    "    }\n",
    "}\n",
    "\n",
    "split = split_dataset(dataset, options)\n",
    "dprint(\"split =\", split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Splitting a Dataset with Custom Split IDs\n",
    "\n",
    "In this section, we split the dataset based on custom sample IDs for each set. We can specify the sample IDs for training, validation, and prediction sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-20 15:37:06,412:WARNING:split.py:split_dataset(89)]:there are some ids present in several splits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Third split\n",
      "split = {\n",
      "     train : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "     val : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "     predict : [25 26 27 28 29 30 31 32 33 34]\n",
      "     other : [20 21 22 23 24 60 61 62 63 64 65 66 67 68 69]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"# Fourth split\")\n",
    "options = {\n",
    "    'split_ids': {\n",
    "        'train': np.arange(20),\n",
    "        'val': np.arange(30, 60),\n",
    "        'predict': np.arange(25, 35),\n",
    "    },\n",
    "}\n",
    "\n",
    "split = split_dataset(dataset, options)\n",
    "dprint(\"split =\", split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
